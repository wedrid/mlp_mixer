{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': '-', 'rand_augm_numops': 3, 'rand_augm_magnitude': 15, 'comment': 'added weight decay', 'train_size': 626, 'validation_size': 25, 'learning_rate': 0.001, 'epochs': 500, 'steps': 626, 'batch_size': 2048, 'mixup_alpha': -1, 'weight_decay': 0.1, 'image_width_and_height': 64, 'patch_width_and_height': 8, 'hidden_dim_size (n_channels)': 128, 'number_of_layers': 8, 'mlp_dc_dimension': 512, 'mlp_ds_dimension': 64}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "MLP_mixer(\n",
       "  (patch_embedder): Conv2d(3, 128, kernel_size=(8, 8), stride=(8, 8))\n",
       "  (mixerlayers): ModuleList(\n",
       "    (0): MixerLayer(\n",
       "      (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (MLP1): MLP(\n",
       "        (linear_gelu_stack): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (MLP2): MLP(\n",
       "        (linear_gelu_stack): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): MixerLayer(\n",
       "      (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (MLP1): MLP(\n",
       "        (linear_gelu_stack): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (MLP2): MLP(\n",
       "        (linear_gelu_stack): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (2): MixerLayer(\n",
       "      (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (MLP1): MLP(\n",
       "        (linear_gelu_stack): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (MLP2): MLP(\n",
       "        (linear_gelu_stack): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (3): MixerLayer(\n",
       "      (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (MLP1): MLP(\n",
       "        (linear_gelu_stack): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (MLP2): MLP(\n",
       "        (linear_gelu_stack): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (4): MixerLayer(\n",
       "      (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (MLP1): MLP(\n",
       "        (linear_gelu_stack): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (MLP2): MLP(\n",
       "        (linear_gelu_stack): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (5): MixerLayer(\n",
       "      (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (MLP1): MLP(\n",
       "        (linear_gelu_stack): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (MLP2): MLP(\n",
       "        (linear_gelu_stack): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (6): MixerLayer(\n",
       "      (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (MLP1): MLP(\n",
       "        (linear_gelu_stack): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (MLP2): MLP(\n",
       "        (linear_gelu_stack): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (7): MixerLayer(\n",
       "      (layer_norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (layer_norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "      (MLP1): MLP(\n",
       "        (linear_gelu_stack): Sequential(\n",
       "          (0): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=64, out_features=64, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (MLP2): MLP(\n",
       "        (linear_gelu_stack): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pre_fc_layernorm): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "  (fc_head): Linear(in_features=128, out_features=100, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from mlp_mixer import * \n",
    "import json\n",
    "\n",
    "####### EVAL PARAMS\n",
    "one_batch = False\n",
    "\n",
    "path = \"./for_time_evaluation/\"\n",
    "with open(path+'edo_out_hyperparams.json') as json_file:\n",
    "    params = json.load(json_file)\n",
    "\n",
    "print(params)\n",
    "\n",
    "image_width_height = params['image_width_and_height'] #da cambiare a seconda della dimensione dell'immagine\n",
    "patch_dims = params['patch_width_and_height']\n",
    "# variable_name = value #paper value\n",
    "n_channels = params['hidden_dim_size (n_channels)'] #10 #512\n",
    "num_layers = params['number_of_layers'] #3\n",
    "mlp_dc_dimension = params['mlp_dc_dimension'] #8 #2048 # dc è la dimensione del channel mixing (l'ultimo mlp)\n",
    "mlp_ds_dimension = params['mlp_ds_dimension'] #8 #256 # ds è la dimensione del token mixing (il primo)\n",
    "\n",
    "model = MLP_mixer(img_h_w=image_width_height, patch_dim=patch_dims, n_channels=n_channels, num_mixers_layers=num_layers,\n",
    "    hidden_dim_mlp_token=mlp_ds_dimension, hidden_dim_mlp_channel=mlp_dc_dimension)\n",
    "\n",
    "#model.load_state_dict(torch.load(path+\"final.pth\"))\n",
    "model.load_state_dict(torch.load(path+\"edo_model_weights.pth\"))\n",
    "model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./for_time_evaluation\n",
      "heads, hidden dim TE:  8 512\n",
      "heads, hidden dim TB:  8 512\n",
      "heads, hidden dim TB:  8 512\n",
      "heads, hidden dim TB:  8 512\n",
      "heads, hidden dim TB:  8 512\n",
      "heads, hidden dim TB:  8 512\n",
      "heads, hidden dim TB:  8 512\n",
      "heads, hidden dim TB:  8 512\n",
      "heads, hidden dim TB:  8 512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "ViT(\n",
       "  (patch_embedding): PatchEmbedding(\n",
       "    (linear_embedding): Linear(in_features=192, out_features=128, bias=True)\n",
       "  )\n",
       "  (position_embedding): PositionEmbedding()\n",
       "  (transformer): TransformerEncoder(\n",
       "    (layers): ModuleList(\n",
       "      (0): TransformerBlock(\n",
       "        (multi_head_attention): MultiHeadAttention(\n",
       "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): TransformerBlock(\n",
       "        (multi_head_attention): MultiHeadAttention(\n",
       "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): TransformerBlock(\n",
       "        (multi_head_attention): MultiHeadAttention(\n",
       "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): TransformerBlock(\n",
       "        (multi_head_attention): MultiHeadAttention(\n",
       "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): TransformerBlock(\n",
       "        (multi_head_attention): MultiHeadAttention(\n",
       "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): TransformerBlock(\n",
       "        (multi_head_attention): MultiHeadAttention(\n",
       "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): TransformerBlock(\n",
       "        (multi_head_attention): MultiHeadAttention(\n",
       "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): TransformerBlock(\n",
       "        (multi_head_attention): MultiHeadAttention(\n",
       "          (values): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (keys): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (queries): Linear(in_features=16, out_features=16, bias=False)\n",
       "          (fc_out): Linear(in_features=128, out_features=128, bias=True)\n",
       "        )\n",
       "        (norm1): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (norm2): LayerNorm((128,), eps=1e-05, elementwise_affine=True)\n",
       "        (feed_forward): Sequential(\n",
       "          (0): Linear(in_features=128, out_features=512, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=512, out_features=128, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (mlp_head): Linear(in_features=128, out_features=100, bias=True)\n",
       "  (dropout): Dropout(p=0.0, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loading of Chiara's model\n",
    "\"\"\" Test finetuned model \"\"\"\n",
    "\n",
    "import torch\n",
    "import json\n",
    "from vit import *\n",
    "\n",
    "# rand aug and scheduling learning rate applied\n",
    "\n",
    "# weights_path = './fine_tuning_vit_cifar100'\n",
    "weights_path = './for_time_evaluation'  # se tutto è nella stessa cartella (vit.py, hyperparams_ft.json, weights_71.pth, e questo file)\n",
    "\n",
    "print(weights_path)\n",
    "\n",
    "with open(weights_path + '/hyperparams_ft.json') as json_file:\n",
    "    hyper_params = json.load(json_file)\n",
    "\n",
    "# Definizione modello\n",
    "model = ViT(img_size=hyper_params['img_size'], embed_dim=hyper_params['embed_dim'], num_channels=3,\n",
    "            num_heads=hyper_params['num_heads'], num_layers=hyper_params['num_layers'],\n",
    "            num_classes=hyper_params['num_classes'], patch_size=hyper_params['patch_size'],\n",
    "            hidden_dim=hyper_params['hidden_dim'], dropout_value=hyper_params['dropout_value'])\n",
    "\n",
    "# print(model)\n",
    "\n",
    "num_in_features = model.embed_dim\n",
    "\n",
    "# add new learnable linear layer\n",
    "model.mlp_head = torch.nn.Linear(num_in_features, hyper_params['num_classes'])\n",
    "# print(model)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "if device == 'cpu':\n",
    "    model.load_state_dict(torch.load(weights_path + '/chiara_model_weights.pth',\n",
    "                                     map_location='cpu'))\n",
    "else:\n",
    "    model.load_state_dict(torch.load(weights_path + '/chiara_model_weights.pth'))\n",
    "\n",
    "model.eval()\n",
    "\n",
    "model.to(device)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "BATCH SIZE: 512\n",
      "Tran subset len: 50000\n",
      "Tran loader len: 98\n",
      "Test: 97.65625\n",
      "Val/test subset len: 10000\n",
      "Val/test subset len: 20\n",
      "Val/Test: 19.53125\n",
      "Test subset len: 10000\n",
      "Test subset len: 20\n",
      "Test: 19.53125\n"
     ]
    }
   ],
   "source": [
    "import torchvision.transforms as transforms\n",
    "from get_dataloaders import * \n",
    "\n",
    "\n",
    "root = './cifar100_data' #if not in lab\n",
    "\n",
    "dataloader_params = {'rand_augm_magnitude': 0, 'rand_augm_numops': 0, 'batch_size':512}\n",
    "one_batch = False\n",
    "if one_batch: \n",
    "    dataloader_params['batch_size'] = 10000\n",
    "else:\n",
    "    dataloader_params['batch_size'] = dataloader_params['batch_size']\n",
    "\n",
    "\n",
    "train_loader, test_loader, _ = getUpsampledCIFAR100Loaders(dataloader_params)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import top_k_accuracy_score\n",
    "\n",
    "\n",
    "def get_top_5_accuracy(predicted, true_labels):\n",
    "    #predicted = torch.argmax(predicted.cpu(), dim=1)\n",
    "    #print(f\"PREDICTED SHAPE: {predicted.shape}, TRUE LABELS: {true_labels.shape} \")\n",
    "    return top_k_accuracy_score(true_labels.cpu(), predicted.cpu(), k = 5, labels=np.arange(predicted.shape[1])) #forse questi passaggi a cpu non sono molto efficienti..\n",
    "\n",
    "def get_accuracy(predicted, true_labels):\n",
    "    predicted = torch.argmax(predicted.cpu(), dim=1)\n",
    "    return accuracy_score(predicted, true_labels.cpu()) #forse questi passaggi a cpu non sono molto efficienti.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a379dade09447fc8c62ab7db9e12126",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0\n",
      "Top 5 accuracy: 0.0\n",
      "Average time = 3.191172158718109\n"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "import numpy as np\n",
    "\n",
    "loss_func = loss_func = nn.CrossEntropyLoss()\n",
    "\n",
    "#processor warmup\n",
    "warmup = False\n",
    "if warmup:\n",
    "    print(\"Processor warmup..\")\n",
    "    for _ in enumerate(tqdm(test_loader)): #numero esempi/batchsize TODO check\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        for _ in range(5):\n",
    "            predicted = model(images)\n",
    "    print(\"..warmed up!\")\n",
    "\n",
    "if device == 'cuda':\n",
    "    torch.cuda.synchronize()\n",
    "\n",
    "times = list()\n",
    "#sm = nn.Softmax(dim = 1)\n",
    "\n",
    "with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_accuracy = 0\n",
    "        val_top_5_acc = 0\n",
    "        temp = 0\n",
    "        for i, (images, labels) in enumerate(tqdm(test_loader)): #numero esempi/batchsize TODO check\n",
    "            images = images.to(device)\n",
    "            labels = labels.to(device)\n",
    "            \n",
    "            # forward pass\n",
    "            start = time.time()\n",
    "            predicted = model(images)\n",
    "            end = time.time()\n",
    "            elapsed = end - start\n",
    "\n",
    "            times.append(elapsed)\n",
    "            #val_accuracy += get_accuracy(predicted, labels)\n",
    "            #val_top_5_acc += get_top_5_accuracy(predicted, labels)\n",
    "        #print(f\"Lenght val loader: {len(val_loader)}, counter: {temp}\")\n",
    "        val_accuracy /= len(test_loader) \n",
    "        val_top_5_acc /= len(test_loader)\n",
    "        print(f\"Accuracy: {val_accuracy}\")\n",
    "        print(f\"Top 5 accuracy: {val_top_5_acc}\")\n",
    "        if one_batch:\n",
    "            print(f\"Elapsed: {elapsed}\")\n",
    "        times = np.array(times)\n",
    "        mean_time = times.mean()\n",
    "        print(f\"Average time = {times.mean()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-3af00cd915f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredicted\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "predicted.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average time per image: 6.232758122496307ms\n"
     ]
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "plt.axhline(y=mean_time, color='r', linestyle='-')\n",
    "plt.plot(np.array(times))\n",
    "\n",
    "plt.title(\"Elapsed time per batch\")\n",
    "plt.xlabel(\"Batch\")\n",
    "plt.ylabel(\"Time (s)\")\n",
    "plt.show()\n",
    "\n",
    "print(f\"Average time per image: {(mean_time/dataloader_params['batch_size'])*1000}ms\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c12a9f36891af4c5b0dfce9e1e49ba1e8afd45b3a8e9c06689a1b7faea4e57c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "19b22627",
   "metadata": {},
   "source": [
    "Hyperparameters definition and loading of CIFAR100 from pytorch torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6e97b3e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Experiment\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "train_portion = 0.7\n",
    "\n",
    "#controllare che len(val) è len(train)\n",
    "\n",
    "#hyperparameters\n",
    "batch_size = 250\n",
    "\n",
    "#pad_totensor_transform = transforms.Compose([transforms.Pad(2), transforms.ToTensor()]) # does the padding, images 32x32 become 36x36 (symmetric increase) so that are divisible by three and patches are 12x12\n",
    "pad_totensor_transform = transforms.Compose([transforms.ToTensor()]) #no pad, no normalization\n",
    "\n",
    "dataset = torchvision.datasets.CIFAR100(root='./cifar100_data', train=True, transform=pad_totensor_transform, download=True)\n",
    "train_subset, val_subset = torch.utils.data.random_split(dataset, [int(train_portion*len(dataset)), len(dataset) - int(train_portion*len(dataset))], generator=torch.Generator().manual_seed(1))\n",
    "test_dataset = torchvision.datasets.CIFAR100(root='./cifar100_data', train=False, transform=pad_totensor_transform)\n",
    "\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_subset, shuffle=True, batch_size=batch_size)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_subset, shuffle=False, batch_size=batch_size)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9047054d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([250, 3, 32, 32]) torch.Size([250])\n",
      "torch.Size([3, 32, 32])\n",
      "torch.Size([3, 32, 32])\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#test dataloader\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples, labels = examples.next()\n",
    "print(samples.shape, labels.shape)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img_sample = samples[0]\n",
    "print(img_sample.shape)\n",
    "print(img_sample.shape)\n",
    "plt.imshow(img_sample.permute(1, 2, 0))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2e7b597",
   "metadata": {},
   "source": [
    "**Training loop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21d9992d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlp_mixer import *\n",
    "from tqdm.notebook import tqdm\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "18b8d606",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy(predicted, true_labels):\n",
    "    predicted = torch.argmax(predicted, dim=1)\n",
    "    return accuracy_score(predicted, true_labels)\n",
    "\n",
    "def save_model(model):\n",
    "    import time\n",
    "    filename = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    filename = \"./models/mlpmixer_\"+filename+\".pth\"\n",
    "    print(filename)\n",
    "    torch.save(model, filename)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3aae0e01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Comet.ml Experiment Summary\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO:   Data:\n",
      "COMET INFO:     display_summary_level : 1\n",
      "COMET INFO:     url                   : https://www.comet.ml/wedrid/mlp-mixer/768c911722f24ebf9eb2ba979f5b0285\n",
      "COMET INFO:   Parameters:\n",
      "COMET INFO:     batch_size                   : 250\n",
      "COMET INFO:     epochs                       : 10\n",
      "COMET INFO:     hidden_dim_size (n_channels) : 512\n",
      "COMET INFO:     image_width_and_height       : 32\n",
      "COMET INFO:     learning_rate                : 0.001\n",
      "COMET INFO:     mlp_dc_dimension             : 2048\n",
      "COMET INFO:     mlp_ds_dimension             : 256\n",
      "COMET INFO:     number_of_layers             : 8\n",
      "COMET INFO:     patch_width_and_height       : 16\n",
      "COMET INFO:     steps                        : 140\n",
      "COMET INFO:     train_size                   : 140\n",
      "COMET INFO:     validation_size              : 60\n",
      "COMET INFO:   Uploads:\n",
      "COMET INFO:     environment details      : 1\n",
      "COMET INFO:     filename                 : 1\n",
      "COMET INFO:     git metadata             : 1\n",
      "COMET INFO:     git-patch (uncompressed) : 1 (63 KB)\n",
      "COMET INFO:     installed packages       : 1\n",
      "COMET INFO: ---------------------------\n",
      "COMET INFO: Experiment is live on comet.ml https://www.comet.ml/wedrid/mlp-mixer/96a3f72cca4149bdaaadd661a27a1fec\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd82b9cfd8e64a7b93dc229ee64e7f26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19aab3a16c7743dfbf64b2deca4813b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of epoch 1: 3.7537\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0539f501c8b14c96a3b88f872d43d694",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b6cb6694647b40bd8de8cf9230d570ad",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of epoch 2: 3.5428\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ef84ff9cfec416987234bd3c6a7b7a8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "241eb1f752554e5396e69be6c88a76f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of epoch 3: 3.4386\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "739e7b4a341343d1a727596aebba1aea",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8fa62435fd3f47e6bf9a6ebf9038c5cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of epoch 4: 3.0906\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941eade0ddbd4dd9a5b330f449bfef49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97c96a4c67e747129d1c0ef24faed71d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of epoch 5: 2.7593\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81be76f6e2924a42b5bcae5a02147549",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3af14dd60260446999f2d3e0ceb5b137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of epoch 6: 2.8658\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fda728fc1c2e4cd6b98611f1cee2333a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0dabd27d44674d5b9fa5692233cbcba4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of epoch 7: 2.7498\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2331da5b0164a6c92fc834641f14b31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f459e5dd918424f86f04a7202b61249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of epoch 8: 2.5932\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a861cf07660140daa4cb700804e5872d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e526cec06f024dc7ab267600f5ba4001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of epoch 9: 2.5319\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "82c79c5a7ac94aa98f538322f838e061",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c98ed481af7f4fea9ca7c3b5ca079328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss of epoch 10: 2.2366\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59c850bab8554ab6bcd209dcdcb8eac1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/60 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".models/mlpmixer_20220308-171942.pth\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '.models/mlpmixer_20220308-171942.pth'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-55955a1c4858>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"val epoch loss\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0mexperiment\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_metric\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"mean val epoch accuracy\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_accuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 84\u001b[0;31m \u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-9-9b6c2f677e6c>\u001b[0m in \u001b[0;36msave_model\u001b[0;34m(model)\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mfilename\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\".models/mlpmixer_\"\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m\".pth\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    374\u001b[0m     \u001b[0m_check_dill_version\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpickle_module\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 376\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'wb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_file\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    377\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m_use_new_zipfile_serialization\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0m_open_zipfile_writer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mopened_zipfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_open_file_like\u001b[0;34m(name_or_buffer, mode)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_open_file_like\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    229\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0m_is_path\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 230\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    231\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/miniconda3/envs/pytorch/lib/python3.8/site-packages/torch/serialization.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, name, mode)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_open_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_opener\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_open_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '.models/mlpmixer_20220308-171942.pth'"
     ]
    }
   ],
   "source": [
    "\n",
    "experiment = Experiment(\n",
    "    api_key=\"xX6qWBFbiOreu0W3IrO14b9nB\",\n",
    "    project_name=\"mlp-mixer\",\n",
    "    workspace=\"wedrid\",\n",
    ")\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "image_width_height = img_sample.shape[1]\n",
    "patch_dims = 16\n",
    "# variable_name = value #paper value\n",
    "n_channels = 100 #512\n",
    "loss_func = nn.CrossEntropyLoss()\n",
    "learning_rate = 0.001\n",
    "num_layers = 8\n",
    "mlp_dc_dimension = 1024 #2048 # dc è la dimensione del channel mixing (l'ultimo mlp)\n",
    "mlp_ds_dimension = 128 #256 # ds è la dimensione del token mixing (il primo)\n",
    "\n",
    "model = MLP_mixer(img_h_w=image_width_height, patch_dim=patch_dims, n_channels=n_channels, num_mixers_layers=num_layers,\n",
    "    hidden_dim_mlp_token=mlp_ds_dimension, hidden_dim_mlp_channel=mlp_dc_dimension) #in this case 2 patches 16x16\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "\n",
    "num_epochs = 1\n",
    "steps_total = len(train_loader)\n",
    "\n",
    "hyper_params = {\n",
    "    \"train_size\": len(train_loader),\n",
    "    \"validation_size\": len(val_loader),\n",
    "    \"learning_rate\": learning_rate,\n",
    "    \"epochs\": num_epochs,\n",
    "    \"steps\": steps_total,\n",
    "    \"batch_size\": batch_size,\n",
    "    \"image_width_and_height\": image_width_height,\n",
    "    \"patch_width_and_height\": patch_dims,\n",
    "    \"hidden_dim_size (n_channels)\": n_channels,\n",
    "    \"number_of_layers\": num_layers,\n",
    "    \"mlp_dc_dimension\": mlp_dc_dimension,\n",
    "    \"mlp_ds_dimension\": mlp_ds_dimension\n",
    "}\n",
    "\n",
    "experiment.log_parameters(hyper_params)\n",
    "\n",
    "# training loop\n",
    "for epoch in tqdm(range(num_epochs)):\n",
    "    model.train()\n",
    "    train_accuracy = 0\n",
    "    for i, (images, labels) in enumerate(tqdm(train_loader)):\n",
    "        # [100, 3, 36, 36] is what is returned by iterator\n",
    "        images = images.to(device)\n",
    "        true_labels = labels.to(device)\n",
    "        \n",
    "        # forward pass\n",
    "        predicted = model(images)\n",
    "        loss = loss_func(predicted, true_labels)\n",
    "        train_accuracy += get_accuracy(predicted, true_labels)\n",
    "\n",
    "        # backwards pass\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if False and (i+1) % 100:\n",
    "            print(f'epoch: {epoch+1} of {num_epochs}, step {i+1} of {steps_total}, loss = {loss.item():.4f}')\n",
    "    print(f\"Loss of epoch {epoch+1}: {loss.item():.4f}\")\n",
    "    train_accuracy /= len(train_loader)\n",
    "    experiment.log_metric(\"train epoch loss\", loss.item(), step=epoch)\n",
    "    experiment.log_metric(\"mean train epoch accuracy\", train_accuracy, step=epoch)\n",
    "    # validation\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        val_accuracy = 0\n",
    "        for i, (images, labels) in enumerate(tqdm(val_loader)):\n",
    "            # [100, 3, 36, 36] is what is returned by iterator\n",
    "            images = images.to(device)\n",
    "            true_labels = labels.to(device)\n",
    "            \n",
    "            # forward pass\n",
    "            predicted = model(images)\n",
    "            loss = loss_func(predicted, true_labels)\n",
    "            val_accuracy += get_accuracy(predicted, true_labels)\n",
    "        val_accuracy /= len(val_loader)\n",
    "        experiment.log_metric(\"val epoch loss\", loss.item(), step=epoch)\n",
    "        experiment.log_metric(\"mean val epoch accuracy\", val_accuracy, step=epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ddcc6cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./models/mlpmixer_20220308-173818.pth\n"
     ]
    }
   ],
   "source": [
    "save_model(model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84652e6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([50, 100])\n",
      "Accuracy 0.1\n",
      "torch.Size([50])\n",
      "tensor([63, 92, 24, 54, 67, 92,  6, 24, 74, 53, 49, 60, 52, 53, 85, 61, 66, 47,\n",
      "        86, 54, 60, 21, 47, 63, 67, 86, 74, 66, 21, 49, 52, 37, 59, 61, 97, 49,\n",
      "        60, 20, 49, 14, 63, 97, 98, 24, 85, 23, 63, 66, 60,  7])\n"
     ]
    }
   ],
   "source": [
    "examples = iter(train_loader)\n",
    "images, labels = examples.next()\n",
    "\n",
    "# metrics trial\n",
    "images = images.to(device)\n",
    "labels = labels.to(device)\n",
    "\n",
    "# forward pass\n",
    "outputs = model(images)\n",
    "loss = loss_func(outputs, labels)\n",
    "\n",
    "#da mettere nel ciclo\n",
    "print(outputs.shape)\n",
    "\n",
    "#####\n",
    "predicted = torch.argmax(outputs, dim=1)\n",
    "accuracy = accuracy_score(predicted, labels)\n",
    "print(f'Accuracy {accuracy}')\n",
    "#####\n",
    "print(predicted.shape)\n",
    "print(predicted)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6c12a9f36891af4c5b0dfce9e1e49ba1e8afd45b3a8e9c06689a1b7faea4e57c"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
